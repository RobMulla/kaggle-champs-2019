{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.layers import BatchNormalization,Add,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(action=\"ignore\",category=FutureWarning)\n",
    "import os\n",
    "import gc\n",
    "#%cd /kaggle/input/champs-scalar-coupling\n",
    "#print(os.listdir(\".\"))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First grab the data.\n",
    "I don't like to clutter up my solution notebooks with my EDA work.  That's usually a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train =pd.read_csv('../input/train.csv')\n",
    "df_test  =pd.read_csv('../input/test.csv')\n",
    "df_struct=pd.read_csv('../input/structures.csv')\n",
    "\n",
    "df_train_sub_charge=pd.read_csv('../input/mulliken_charges.csv')\n",
    "df_train_sub_tensor=pd.read_csv('../input/magnetic_shielding_tensors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the Memory Usage\n",
    "Without this call, this kernel definitely can't be run on smaller cloud instances... I always test solutions on CoLaboratory to see if low-resource nodes can process them.  In this case, CoLab can't unless you reduce down.  The results seem similar to when the same network is trained on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4658147, 6) (2505542, 5) (2358657, 6) (1533537, 3) (1533537, 11)\n",
      "Mem. usage decreased to 106.62 Mb (50.0% reduction)\n",
      "Mem. usage decreased to 52.57 Mb (45.0% reduction)\n",
      "Mem. usage decreased to 51.74 Mb (52.1% reduction)\n",
      "Mem. usage decreased to 16.09 Mb (54.2% reduction)\n",
      "Mem. usage decreased to 39.49 Mb (69.3% reduction)\n",
      "(4658147, 6) (2505542, 5) (2358657, 6) (1533537, 3) (1533537, 11)\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "print(df_train.shape, df_test.shape, df_struct.shape, df_train_sub_charge.shape, df_train_sub_tensor.shape)\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "df_struct = reduce_mem_usage(df_struct)\n",
    "df_train_sub_charge = reduce_mem_usage(df_train_sub_charge)\n",
    "df_train_sub_tensor = reduce_mem_usage(df_train_sub_tensor)\n",
    "print(df_train.shape, df_test.shape, df_struct.shape, df_train_sub_charge.shape, df_train_sub_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map data into a master dataframe\n",
    "Here's the code to do mappings.  The drop_duplicates is important, else your test dataset will grow and your predictions will not be output correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM usage: 0.7256965637207031 GB\n",
      "Mapping... (4658147, 6) (2358657, 6) 0\n",
      "Mapping... (4658147, 10) (1533537, 3) 0\n",
      "Mapping... (4658147, 11) (1533537, 11) 0\n",
      "Mapping... (2505542, 5) (2358657, 6) 0\n",
      "RAM usage: 1.3466949462890625 GB\n",
      "(4658147, 20) (2505542, 9)\n",
      "Mapping... (4658147, 20) (2358657, 10) 1\n",
      "Mapping... (4658147, 28) (1533537, 3) 1\n",
      "Mapping... (4658147, 29) (1533537, 11) 1\n",
      "Mapping... (2505542, 9) (2358657, 10) 1\n",
      "RAM usage: 1.4347801208496094 GB\n",
      "(4658147, 38) (2505542, 17)\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Map atom info from the structures.csv into the train/test files\n",
    "'''\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    print('Mapping...', df_1.shape, df_2.shape, atom_idx)\n",
    "    \n",
    "    df = pd.merge(df_1, df_2.drop_duplicates(subset=['molecule_name', 'atom_index']), how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    \n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def show_ram_usage():\n",
    "    py = psutil.Process(os.getpid())\n",
    "    print('RAM usage: {} GB'.format(py.memory_info()[0]/2. ** 30))\n",
    "\n",
    "show_ram_usage()\n",
    "\n",
    "for atom_idx in [0,1]:\n",
    "    df_train = map_atom_info(df_train,df_struct, atom_idx)\n",
    "    df_train = map_atom_info(df_train,df_train_sub_charge, atom_idx)\n",
    "    df_train = map_atom_info(df_train,df_train_sub_tensor, atom_idx)\n",
    "    df_train = df_train.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "                                        'x': f'x_{atom_idx}',\n",
    "                                        'y': f'y_{atom_idx}',\n",
    "                                        'z': f'z_{atom_idx}',\n",
    "                                        'mulliken_charge': f'charge_{atom_idx}',\n",
    "                                        'XX': f'XX_{atom_idx}',\n",
    "                                        'YX': f'YX_{atom_idx}',\n",
    "                                        'ZX': f'ZX_{atom_idx}',\n",
    "                                        'XY': f'XY_{atom_idx}',\n",
    "                                        'YY': f'YY_{atom_idx}',\n",
    "                                        'ZY': f'ZY_{atom_idx}',\n",
    "                                        'XZ': f'XZ_{atom_idx}',\n",
    "                                        'YZ': f'YZ_{atom_idx}',\n",
    "                                        'ZZ': f'ZZ_{atom_idx}',})\n",
    "    df_test = map_atom_info(df_test,df_struct, atom_idx)\n",
    "    df_test = df_test.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "                                'x': f'x_{atom_idx}',\n",
    "                                'y': f'y_{atom_idx}',\n",
    "                                'z': f'z_{atom_idx}'})\n",
    "    #add some features\n",
    "    \n",
    "    df_struct['c_x']=df_struct.groupby('molecule_name')['x'].transform('mean')\n",
    "    df_struct['c_y']=df_struct.groupby('molecule_name')['y'].transform('mean')\n",
    "    df_struct['c_z']=df_struct.groupby('molecule_name')['z'].transform('mean')\n",
    "    df_struct['atom_n']=df_struct.groupby('molecule_name')['atom_index'].transform('max')\n",
    "    \n",
    "    show_ram_usage()\n",
    "    print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start developing more complex features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM usage: 1.4354248046875 GB\n",
      "(4658147, 42) (2505542, 21)\n",
      "Mapping... (2505542, 21) (790486, 8) 0\n",
      "Mapping... (2505542, 27) (790486, 8) 1\n",
      "Mapping... (2505542, 33) (775149, 8) 0\n",
      "Mapping... (2505542, 39) (775149, 8) 1\n",
      "Mapping... (4658147, 42) (1468792, 8) 0\n",
      "Mapping... (4658147, 48) (1468792, 8) 1\n",
      "Mapping... (4658147, 54) (1440019, 8) 0\n",
      "Mapping... (4658147, 60) (1440019, 8) 1\n",
      "(4658147, 66) (2505542, 45)\n",
      "RAM usage: 2.038860321044922 GB\n"
     ]
    }
   ],
   "source": [
    "def make_features(df):\n",
    "    df['dx']=df['x_1']-df['x_0']\n",
    "    df['dy']=df['y_1']-df['y_0']\n",
    "    df['dz']=df['z_1']-df['z_0']\n",
    "    df['distance']=(df['dx']**2+df['dy']**2+df['dz']**2)**(1/2)\n",
    "    return df\n",
    "\n",
    "df_train=make_features(df_train)\n",
    "df_test=make_features(df_test) \n",
    "#df_train = reduce_mem_usage(df_train)\n",
    "#df_test = reduce_mem_usage(df_test)\n",
    "test_prediction=np.zeros(len(df_test))\n",
    "show_ram_usage()\n",
    "print(df_train.shape, df_test.shape)\n",
    "\n",
    "def get_dist(df):\n",
    "    df_temp=df.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"distance\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
    "                                       'atom_index_1': 'atom_index_0',\n",
    "                                       'x_0': 'x_1',\n",
    "                                       'y_0': 'y_1',\n",
    "                                       'z_0': 'z_1',\n",
    "                                       'x_1': 'x_0',\n",
    "                                       'y_1': 'y_0',\n",
    "                                       'z_1': 'z_0'})\n",
    "    df_temp_all=pd.concat((df_temp,df_temp_),axis=0)\n",
    "\n",
    "    df_temp_all[\"min_distance\"]=df_temp_all.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('min')\n",
    "    df_temp_all[\"max_distance\"]=df_temp_all.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('max')\n",
    "    \n",
    "    df_temp= df_temp_all[df_temp_all[\"min_distance\"]==df_temp_all[\"distance\"]].copy()\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                         'atom_index_1': 'atom_index_closest',\n",
    "                                         'distance': 'distance_closest',\n",
    "                                         'x_1': 'x_closest',\n",
    "                                         'y_1': 'y_closest',\n",
    "                                         'z_1': 'z_closest'})\n",
    "    \n",
    "    for atom_idx in [0,1]:\n",
    "        df = map_atom_info(df,df_temp, atom_idx)\n",
    "        df = df.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                        'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                        'x_closest': f'x_closest_{atom_idx}',\n",
    "                                        'y_closest': f'y_closest_{atom_idx}',\n",
    "                                        'z_closest': f'z_closest_{atom_idx}'})\n",
    "        \n",
    "    df_temp= df_temp_all[df_temp_all[\"max_distance\"]==df_temp_all[\"distance\"]].copy()\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','max_distance'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                         'atom_index_1': 'atom_index_farthest',\n",
    "                                         'distance': 'distance_farthest',\n",
    "                                         'x_1': 'x_farthest',\n",
    "                                         'y_1': 'y_farthest',\n",
    "                                         'z_1': 'z_farthest'})\n",
    "        \n",
    "    for atom_idx in [0,1]:\n",
    "        df = map_atom_info(df,df_temp, atom_idx)\n",
    "        df = df.rename(columns={'atom_index_farthest': f'atom_index_farthest_{atom_idx}',\n",
    "                                        'distance_farthest': f'distance_farthest_{atom_idx}',\n",
    "                                        'x_farthest': f'x_farthest_{atom_idx}',\n",
    "                                        'y_farthest': f'y_farthest_{atom_idx}',\n",
    "                                        'z_farthest': f'z_farthest_{atom_idx}'})\n",
    "    return df\n",
    "df_test=(get_dist(df_test))    \n",
    "df_train=(get_dist(df_train)) \n",
    "\n",
    "print(df_train.shape, df_test.shape)\n",
    "show_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is where the Cosine Distance features are Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4658147, 81) (2505542, 60)\n",
      "RAM usage: 2.0719871520996094 GB\n"
     ]
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    df[\"distance_center0\"]=((df['x_0']-df['c_x'])**2+(df['y_0']-df['c_y'])**2+(df['z_0']-df['c_z'])**2)**(1/2)\n",
    "    df[\"distance_center1\"]=((df['x_1']-df['c_x'])**2+(df['y_1']-df['c_y'])**2+(df['z_0']-df['c_z'])**2)**(1/2)\n",
    "    df[\"distance_c0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_c1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    df[\"distance_f0\"]=((df['x_0']-df['x_farthest_0'])**2+(df['y_0']-df['y_farthest_0'])**2+(df['z_0']-df['z_farthest_0'])**2)**(1/2)\n",
    "    df[\"distance_f1\"]=((df['x_1']-df['x_farthest_1'])**2+(df['y_1']-df['y_farthest_1'])**2+(df['z_1']-df['z_farthest_1'])**2)**(1/2)\n",
    "    df[\"vec_center0_x\"]=(df['x_0']-df['c_x'])/(df[\"distance_center0\"]+1e-10)\n",
    "    df[\"vec_center0_y\"]=(df['y_0']-df['c_y'])/(df[\"distance_center0\"]+1e-10)\n",
    "    df[\"vec_center0_z\"]=(df['z_0']-df['c_z'])/(df[\"distance_center0\"]+1e-10)\n",
    "    df[\"vec_center1_x\"]=(df['x_1']-df['c_x'])/(df[\"distance_center1\"]+1e-10)\n",
    "    df[\"vec_center1_y\"]=(df['y_1']-df['c_y'])/(df[\"distance_center1\"]+1e-10)\n",
    "    df[\"vec_center1_z\"]=(df['z_1']-df['c_z'])/(df[\"distance_center1\"]+1e-10)\n",
    "    df[\"vec_c0_x\"]=(df['x_0']-df['x_closest_0'])/(df[\"distance_c0\"]+1e-10)\n",
    "    df[\"vec_c0_y\"]=(df['y_0']-df['y_closest_0'])/(df[\"distance_c0\"]+1e-10)\n",
    "    df[\"vec_c0_z\"]=(df['z_0']-df['z_closest_0'])/(df[\"distance_c0\"]+1e-10)\n",
    "    df[\"vec_c1_x\"]=(df['x_1']-df['x_closest_1'])/(df[\"distance_c1\"]+1e-10)\n",
    "    df[\"vec_c1_y\"]=(df['y_1']-df['y_closest_1'])/(df[\"distance_c1\"]+1e-10)\n",
    "    df[\"vec_c1_z\"]=(df['z_1']-df['z_closest_1'])/(df[\"distance_c1\"]+1e-10)\n",
    "    df[\"vec_f0_x\"]=(df['x_0']-df['x_farthest_0'])/(df[\"distance_f0\"]+1e-10)\n",
    "    df[\"vec_f0_y\"]=(df['y_0']-df['y_farthest_0'])/(df[\"distance_f0\"]+1e-10)\n",
    "    df[\"vec_f0_z\"]=(df['z_0']-df['z_farthest_0'])/(df[\"distance_f0\"]+1e-10)\n",
    "    df[\"vec_f1_x\"]=(df['x_1']-df['x_farthest_1'])/(df[\"distance_f1\"]+1e-10)\n",
    "    df[\"vec_f1_y\"]=(df['y_1']-df['y_farthest_1'])/(df[\"distance_f1\"]+1e-10)\n",
    "    df[\"vec_f1_z\"]=(df['z_1']-df['z_farthest_1'])/(df[\"distance_f1\"]+1e-10)\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"distance\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"distance\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"distance\"]\n",
    "    df[\"cos_c0_c1\"]=df[\"vec_c0_x\"]*df[\"vec_c1_x\"]+df[\"vec_c0_y\"]*df[\"vec_c1_y\"]+df[\"vec_c0_z\"]*df[\"vec_c1_z\"]\n",
    "    df[\"cos_f0_f1\"]=df[\"vec_f0_x\"]*df[\"vec_f1_x\"]+df[\"vec_f0_y\"]*df[\"vec_f1_y\"]+df[\"vec_f0_z\"]*df[\"vec_f1_z\"]\n",
    "    df[\"cos_center0_center1\"]=df[\"vec_center0_x\"]*df[\"vec_center1_x\"]+df[\"vec_center0_y\"]*df[\"vec_center1_y\"]+df[\"vec_center0_z\"]*df[\"vec_center1_z\"]\n",
    "    df[\"cos_c0\"]=df[\"vec_c0_x\"]*df[\"vec_x\"]+df[\"vec_c0_y\"]*df[\"vec_y\"]+df[\"vec_c0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_c1\"]=df[\"vec_c1_x\"]*df[\"vec_x\"]+df[\"vec_c1_y\"]*df[\"vec_y\"]+df[\"vec_c1_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_f0\"]=df[\"vec_f0_x\"]*df[\"vec_x\"]+df[\"vec_f0_y\"]*df[\"vec_y\"]+df[\"vec_f0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_f1\"]=df[\"vec_f1_x\"]*df[\"vec_x\"]+df[\"vec_f1_y\"]*df[\"vec_y\"]+df[\"vec_f1_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_center0\"]=df[\"vec_center0_x\"]*df[\"vec_x\"]+df[\"vec_center0_y\"]*df[\"vec_y\"]+df[\"vec_center0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_center1\"]=df[\"vec_center1_x\"]*df[\"vec_x\"]+df[\"vec_center1_y\"]*df[\"vec_y\"]+df[\"vec_center1_z\"]*df[\"vec_z\"]\n",
    "    df=df.drop(['vec_c0_x','vec_c0_y','vec_c0_z','vec_c1_x','vec_c1_y','vec_c1_z',\n",
    "                'vec_f0_x','vec_f0_y','vec_f0_z','vec_f1_x','vec_f1_y','vec_f1_z',\n",
    "                'vec_center0_x','vec_center0_y','vec_center0_z','vec_center1_x','vec_center1_y','vec_center1_z',\n",
    "                'vec_x','vec_y','vec_z'], axis=1)\n",
    "    return df\n",
    "    \n",
    "df_train=add_features(df_train)\n",
    "df_test=add_features(df_test)\n",
    "print(df_train.shape, df_test.shape)\n",
    "show_ram_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here you add the external extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = '1JHC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FE021_train_1JHC = pd.read_parquet('../data/FE021/FE021-train-1JHC.parquet', engine='pyarrow')\n",
    "FE021_test_1JHC = pd.read_parquet('../data/FE021/FE021-test-1JHC.parquet', engine='pyarrow')\n",
    "\n",
    "FE021_train_1JHN = pd.read_parquet('../data/FE021/FE021-train-1JHN.parquet', engine='pyarrow')\n",
    "FE021_test_1JHN = pd.read_parquet('../data/FE021/FE021-test-1JHN.parquet', engine='pyarrow')\n",
    "\n",
    "FE021_train_2JHH = pd.read_parquet('../data/FE021/FE021-train-2JHH.parquet', engine='pyarrow')\n",
    "FE021_test_2JHH = pd.read_parquet('../data/FE021/FE021-test-2JHH.parquet', engine='pyarrow')\n",
    "\n",
    "FE021_train_2JHC = pd.read_parquet('../data/FE021/FE021-train-2JHC.parquet', engine='pyarrow')\n",
    "FE021_test_2JHC = pd.read_parquet('../data/FE021/FE021-test-2JHC.parquet', engine='pyarrow')\n",
    "\n",
    "FE021_train_2JHN = pd.read_parquet('../data/FE021/FE021-train-2JHN.parquet', engine='pyarrow')\n",
    "FE021_test_2JHN = pd.read_parquet('../data/FE021/FE021-test-2JHN.parquet', engine='pyarrow')\n",
    "\n",
    "FE021_train_3JHH = pd.read_parquet('../data/FE021/FE021-train-3JHH.parquet', engine='pyarrow')\n",
    "FE021_test_3JHH = pd.read_parquet('../data/FE021/FE021-test-3JHH.parquet', engine='pyarrow')\n",
    "\n",
    "FE021_train_3JHC = pd.read_parquet('../data/FE021/FE021-train-3JHC.parquet', engine='pyarrow')\n",
    "FE021_test_3JHC = pd.read_parquet('../data/FE021/FE021-test-3JHC.parquet', engine='pyarrow')\n",
    "\n",
    "FE021_train_3JHN = pd.read_parquet('../data/FE021/FE021-train-3JHN.parquet', engine='pyarrow')\n",
    "FE021_test_3JHN = pd.read_parquet('../data/FE021/FE021-test-3JHN.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_raw_type = train_raw.loc[train_raw['type'] == bond_type].reset_index(drop=True)\n",
    "#train_df = pd.concat([train_raw_type, train_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train6.drop( ['id','typei'], inplace=True, axis=1 )\n",
    "# test6.drop(  ['id','typei'], inplace=True, axis=1 )\n",
    "# train6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>atom_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>...</th>\n",
       "      <th>distance_f1</th>\n",
       "      <th>cos_c0_c1</th>\n",
       "      <th>cos_f0_f1</th>\n",
       "      <th>cos_center0_center1</th>\n",
       "      <th>cos_c0</th>\n",
       "      <th>cos_c1</th>\n",
       "      <th>cos_f0</th>\n",
       "      <th>cos_f1</th>\n",
       "      <th>cos_center0</th>\n",
       "      <th>cos_center1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.812500</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.091797</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.816406</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.816406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257812</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>-0.333496</td>\n",
       "      <td>-0.500488</td>\n",
       "      <td>-0.333496</td>\n",
       "      <td>-0.816406</td>\n",
       "      <td>0.817383</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500488</td>\n",
       "      <td>-0.816406</td>\n",
       "      <td>0.817383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257812</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>-0.333252</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.567871</td>\n",
       "      <td>-0.816406</td>\n",
       "      <td>0.816895</td>\n",
       "      <td>-0.499756</td>\n",
       "      <td>0.500488</td>\n",
       "      <td>-0.816895</td>\n",
       "      <td>1.392578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257812</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783203</td>\n",
       "      <td>-0.333008</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.585449</td>\n",
       "      <td>-0.816406</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>-0.816406</td>\n",
       "      <td>1.435547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.812500</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011719</td>\n",
       "      <td>1.463867</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>...</td>\n",
       "      <td>1.091797</td>\n",
       "      <td>0.333496</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>-1.000977</td>\n",
       "      <td>-0.333496</td>\n",
       "      <td>-0.816895</td>\n",
       "      <td>-0.333496</td>\n",
       "      <td>-1.000977</td>\n",
       "      <td>-0.007412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0   0  dsgdb9nsd_000001             1             0  1JHC   \n",
       "1   1  dsgdb9nsd_000001             1             2  2JHH   \n",
       "2   2  dsgdb9nsd_000001             1             3  2JHH   \n",
       "3   3  dsgdb9nsd_000001             1             4  2JHH   \n",
       "4   4  dsgdb9nsd_000001             2             0  1JHC   \n",
       "\n",
       "   scalar_coupling_constant atom_0       x_0       y_0       z_0  ...  \\\n",
       "0                 84.812500      H  0.002150 -0.006031  0.001976  ...   \n",
       "1                -11.257812      H  0.002150 -0.006031  0.001976  ...   \n",
       "2                -11.257812      H  0.002150 -0.006031  0.001976  ...   \n",
       "3                -11.257812      H  0.002150 -0.006031  0.001976  ...   \n",
       "4                 84.812500      H  1.011719  1.463867  0.000277  ...   \n",
       "\n",
       "   distance_f1  cos_c0_c1  cos_f0_f1  cos_center0_center1    cos_c0    cos_c1  \\\n",
       "0     1.091797  -1.000000  -0.816406             0.000145 -1.000000  1.000000   \n",
       "1     1.783203  -0.333496  -0.500488            -0.333496 -0.816406  0.817383   \n",
       "2     1.783203  -0.333252  -0.000041            -0.567871 -0.816406  0.816895   \n",
       "3     1.783203  -0.333008  -0.500000            -0.585449 -0.816406  0.816406   \n",
       "4     1.091797   0.333496   0.000189             0.007412 -1.000977 -0.333496   \n",
       "\n",
       "     cos_f0    cos_f1  cos_center0  cos_center1  \n",
       "0 -0.816406  1.000000    -1.000000    -0.000144  \n",
       "1 -1.000000  0.500488    -0.816406     0.817383  \n",
       "2 -0.499756  0.500488    -0.816895     1.392578  \n",
       "3 -0.500000  0.999512    -0.816406     1.435547  \n",
       "4 -0.816895 -0.333496    -1.000977    -0.007412  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sort_values('id', inplace=True)\n",
    "df_test.sort_values( 'id', inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_case = df_train.loc[df_train.type==case, :].reset_index(drop=True)\n",
    "df_test_case = df_test.loc[df_test.type==case, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709416, 709416, 380609)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_case), len(FE021_train_1JHC), len(df_test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10th_closest_to_1_valence_x_cube_inv_dist</th>\n",
       "      <th>12th_closest_to_1_valence</th>\n",
       "      <th>13th_closest_to_1_exact_mass</th>\n",
       "      <th>17th_closest_to_0_spin_multiplicity</th>\n",
       "      <th>17th_closest_to_0_valence</th>\n",
       "      <th>17th_closest_to_0_valence_x_cube_inv_dist</th>\n",
       "      <th>17th_closest_to_1_spin_multiplicity</th>\n",
       "      <th>18th_closest_to_0_exact_mass</th>\n",
       "      <th>19th_closest_to_0_spin_multiplicity</th>\n",
       "      <th>19th_closest_to_1_spin_multiplicity_x_cube_inv_dist</th>\n",
       "      <th>...</th>\n",
       "      <th>tor_ang_2leftleft_count</th>\n",
       "      <th>tor_ang_2leftleft_max</th>\n",
       "      <th>tor_ang_2leftleft_min</th>\n",
       "      <th>val_not_0_mean</th>\n",
       "      <th>val_not_1_mean</th>\n",
       "      <th>val_not_1_std</th>\n",
       "      <th>yukawa_H.x</th>\n",
       "      <th>yukawa_H.y</th>\n",
       "      <th>yukawa_N.x</th>\n",
       "      <th>yukawa_O.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08638</td>\n",
       "      <td>1.969477</td>\n",
       "      <td>6.210087</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>1.538449</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>3.800028</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>4.615952</td>\n",
       "      <td>125.460482</td>\n",
       "      <td>-124.658907</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504328</td>\n",
       "      <td>1.342247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08638</td>\n",
       "      <td>1.969477</td>\n",
       "      <td>6.210087</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>1.538449</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>3.800028</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>4.615952</td>\n",
       "      <td>125.460482</td>\n",
       "      <td>-124.658907</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504327</td>\n",
       "      <td>1.342247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08638</td>\n",
       "      <td>1.969477</td>\n",
       "      <td>6.210087</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>1.538449</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>3.800028</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>4.615952</td>\n",
       "      <td>125.460482</td>\n",
       "      <td>-124.658907</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504323</td>\n",
       "      <td>1.342247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.08638</td>\n",
       "      <td>1.969477</td>\n",
       "      <td>6.210087</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>1.538449</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>3.800028</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>4.615952</td>\n",
       "      <td>125.460482</td>\n",
       "      <td>-124.658907</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504323</td>\n",
       "      <td>1.342247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08638</td>\n",
       "      <td>1.969477</td>\n",
       "      <td>6.210087</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>1.538449</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>3.800028</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>4.615952</td>\n",
       "      <td>125.460482</td>\n",
       "      <td>-124.658907</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344177</td>\n",
       "      <td>0.108789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 351 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10th_closest_to_1_valence_x_cube_inv_dist  12th_closest_to_1_valence  \\\n",
       "0                                    0.08638                   1.969477   \n",
       "1                                    0.08638                   1.969477   \n",
       "2                                    0.08638                   1.969477   \n",
       "3                                    0.08638                   1.969477   \n",
       "4                                    0.08638                   1.969477   \n",
       "\n",
       "   13th_closest_to_1_exact_mass  17th_closest_to_0_spin_multiplicity  \\\n",
       "0                      6.210087                             0.001063   \n",
       "1                      6.210087                             0.001063   \n",
       "2                      6.210087                             0.001063   \n",
       "3                      6.210087                             0.001063   \n",
       "4                      6.210087                             0.001063   \n",
       "\n",
       "   17th_closest_to_0_valence  17th_closest_to_0_valence_x_cube_inv_dist  \\\n",
       "0                   1.538449                                   0.013848   \n",
       "1                   1.538449                                   0.013848   \n",
       "2                   1.538449                                   0.013848   \n",
       "3                   1.538449                                   0.013848   \n",
       "4                   1.538449                                   0.013848   \n",
       "\n",
       "   17th_closest_to_1_spin_multiplicity  18th_closest_to_0_exact_mass  \\\n",
       "0                             0.001074                      3.800028   \n",
       "1                             0.001074                      3.800028   \n",
       "2                             0.001074                      3.800028   \n",
       "3                             0.001074                      3.800028   \n",
       "4                             0.001074                      3.800028   \n",
       "\n",
       "   19th_closest_to_0_spin_multiplicity  \\\n",
       "0                              0.00024   \n",
       "1                              0.00024   \n",
       "2                              0.00024   \n",
       "3                              0.00024   \n",
       "4                              0.00024   \n",
       "\n",
       "   19th_closest_to_1_spin_multiplicity_x_cube_inv_dist  ...  \\\n",
       "0                                           0.000003    ...   \n",
       "1                                           0.000003    ...   \n",
       "2                                           0.000003    ...   \n",
       "3                                           0.000003    ...   \n",
       "4                                           0.000003    ...   \n",
       "\n",
       "   tor_ang_2leftleft_count  tor_ang_2leftleft_max  tor_ang_2leftleft_min  \\\n",
       "0                 4.615952             125.460482            -124.658907   \n",
       "1                 4.615952             125.460482            -124.658907   \n",
       "2                 4.615952             125.460482            -124.658907   \n",
       "3                 4.615952             125.460482            -124.658907   \n",
       "4                 4.615952             125.460482            -124.658907   \n",
       "\n",
       "   val_not_0_mean  val_not_1_mean  val_not_1_std  yukawa_H.x  yukawa_H.y  \\\n",
       "0            1.75             1.0            0.0    0.504328    1.342247   \n",
       "1            1.75             1.0            0.0    0.504327    1.342247   \n",
       "2            1.75             1.0            0.0    0.504323    1.342247   \n",
       "3            1.75             1.0            0.0    0.504323    1.342247   \n",
       "4            1.50             1.0            0.0    0.000000    0.344177   \n",
       "\n",
       "   yukawa_N.x  yukawa_O.y  \n",
       "0    0.000000         0.0  \n",
       "1    0.000000         0.0  \n",
       "2    0.000000         0.0  \n",
       "3    0.000000         0.0  \n",
       "4    0.108789         0.0  \n",
       "\n",
       "[5 rows x 351 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Impute NA with mean\n",
    "\n",
    "MEAN = pd.concat([FE021_train_1JHC,FE021_test_1JHC]).mean()\n",
    "FE021_train_1JHC.fillna( value=MEAN, inplace=True )\n",
    "FE021_test_1JHC.fillna( value=MEAN, inplace=True )\n",
    "FE021_train_1JHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train.shape)\n",
    "df_train_case_final = pd.concat( [df_train_case,FE021_train_1JHC], axis=1 )\n",
    "df_test_case_final  = pd.concat( [df_test_case ,FE021_test_1JHC ], axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709416, 380609)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_case_final), len(df_test_case_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10th_closest_to_1_valence_x_cube_inv_dist',\n",
       " '12th_closest_to_1_valence',\n",
       " '13th_closest_to_1_exact_mass',\n",
       " '17th_closest_to_0_spin_multiplicity',\n",
       " '17th_closest_to_0_valence',\n",
       " '17th_closest_to_0_valence_x_cube_inv_dist',\n",
       " '17th_closest_to_1_spin_multiplicity',\n",
       " '18th_closest_to_0_exact_mass',\n",
       " '19th_closest_to_0_spin_multiplicity',\n",
       " '19th_closest_to_1_spin_multiplicity_x_cube_inv_dist']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_featus =  list(df_train_case_final.columns[81:])\n",
    "extra_featus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network definition\n",
    "\n",
    "This neural network is many layers.  In the middle we define our outputs for our two Mullikan charges as well as our Dipole Moment.  The final output is the one we care the most about, the Scalar Coupling Constant.\n",
    "\n",
    "I think that BatchNormalization at each layer seems superior than small amounts of dropouts.  The network seems to not overfit, even in large numbers of training epochs.  If you do wind up seeing some overfitting, then adding the dropout to a couple of layers ought to help a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn_model(input_shape):\n",
    "    inp = Input(shape=(input_shape,))\n",
    "    x = Dense(1024)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.10)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.10)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.10)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "#     x = Dense(256)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.05)(x)\n",
    "#     #x = Dropout(0.4)(x)\n",
    "#     x = Dense(256)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.05)(x)\n",
    "    #x = Dropout(0.4)(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.10)(x)\n",
    "    #x = Dropout(0.4)(x)\n",
    "    out1 = Dense(2, activation=\"linear\",name='outM2')(x)#mulliken charge 2\n",
    "    out2 = Dense(6, activation=\"linear\",name='outT6')(x)#tensor 6(xx,yy,zz)\n",
    "    out3 = Dense(12, activation=\"linear\",name='outT12')(x)#tensor 12(others) \n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.10)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.10)(x)\n",
    "#     x = Dense(128)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.05)(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation=\"linear\",name='out')(x)#scalar_coupling_constant    \n",
    "    model = Model(inputs=inp, outputs=[out,out1,out2,out3])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/robmulla/anaconda3/envs/kaggle/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/robmulla/anaconda3/envs/kaggle/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         11264       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1024)         4096        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 1024)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         1049600     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1024)         4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 1024)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024)         4096        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1024)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          262400      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128)          512         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 128)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 1)            129         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "outM2 (Dense)                   (None, 2)            2050        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "outT6 (Dense)                   (None, 6)            6150        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "outT12 (Dense)                  (None, 12)           12300       leaky_re_lu_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,493,909\n",
      "Trainable params: 3,484,949\n",
      "Non-trainable params: 8,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model=create_nn_model( 10 )\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Function\n",
    "I rely a lot on loss plots to detect when learning has stopped as well as when overfitting begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, label):\n",
    "    plt.plot(history.history['loss'][-100:])\n",
    "    plt.plot(history.history['val_loss'][-100:])\n",
    "    plt.title('Loss for %s' % label)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    _= plt.legend(['Train','Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931629"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = df_train.id%5\n",
    "len(np.where(splits==4)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f85864170562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_' is not defined"
     ]
    }
   ],
   "source": [
    "len(df_train), len(df_train_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Routine\n",
    "\n",
    "A bunch of stuff happens here.  Pay attention to the callbacks.  I train a different model for each molecule type, which allows for future retraining.  If you have kept your network the same (except for dropout, etc.), and want to retrain for a few more epochs without having to go back to the beginning, then set the retrain flag to False and it will grab the trained models as starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1JHC out of ['1JHC'] \n",
      "\n",
      "(567515, 387) (141901, 387)\n",
      "WARNING:tensorflow:From /home/robmulla/anaconda3/envs/kaggle/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 567515 samples, validate on 141901 samples\n",
      "Epoch 1/500\n",
      " - 155s - loss: 64.7662 - out_loss: 62.2774 - outM2_loss: 0.2724 - outT6_loss: 1.4888 - outT12_loss: 0.7276 - val_loss: 8.0851 - val_out_loss: 5.6313 - val_outM2_loss: 0.3295 - val_outT6_loss: 1.4008 - val_outT12_loss: 0.7235\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-658f875bb0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m                            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                            verbose=verbose)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mcv_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#mol_types=df_train[\"type\"].unique()\n",
    "mol_types = ['1JHC']\n",
    "cv_score=[]\n",
    "cv_score_total=0 \n",
    "epoch_n = 500 # 300\n",
    "verbose = 2\n",
    "batch_size = 1024 # 512\n",
    "    \n",
    "# Set to True if we want to train from scratch.  False will reuse saved models as a starting point.\n",
    "retrain = False\n",
    "\n",
    "\n",
    "# Set up GPU preferences\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1} ) \n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "sess = tf.Session(config=config) \n",
    "K.set_session(sess)\n",
    "\n",
    "start_time=datetime.now()\n",
    "\n",
    "# Loop through each molecule type\n",
    "for mol_type in mol_types:\n",
    "    model_name_rd = ('../keras-neural-net-for-champs/molecule_model_%s.hdf5' % mol_type)\n",
    "    model_name_wrt = ('molecule_model_%s.hdf5' % mol_type)\n",
    "    print('Training %s' % mol_type, 'out of', mol_types, '\\n')\n",
    "    \n",
    "    df_train_ = df_train_case_final[ df_train_case_final[\"type\"]==mol_type]\n",
    "    df_test_  = df_test_case_final [ df_test_case_final[\"type\"]==mol_type]\n",
    "    splits = df_train_.id%5\n",
    "\n",
    "    # Here's our best features.  We think.\n",
    "    input_features=[\n",
    "        \"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\",\"c_x\",\"c_y\",\"c_z\",\n",
    "                    'x_closest_0','y_closest_0','z_closest_0','x_closest_1','y_closest_1','z_closest_1',\n",
    "                    \"distance\",\"distance_center0\",\"distance_center1\", \"distance_c0\",\"distance_c1\",\"distance_f0\",\"distance_f1\",\n",
    "                    \"cos_c0_c1\",\"cos_f0_f1\",\"cos_center0_center1\",\"cos_c0\",\"cos_c1\",\"cos_f0\",\"cos_f1\",\"cos_center0\",\"cos_center1\",\n",
    "\n",
    "    ] + extra_featus\n",
    "\n",
    "    # Standard Scaler from sklearn does seem to work better here than other Scalers\n",
    "    input_data=StandardScaler().fit_transform(pd.concat([df_train_.loc[:,input_features],df_test_.loc[:,input_features]]))\n",
    "    \n",
    "    target_data=df_train_.loc[:,\"scalar_coupling_constant\"].values\n",
    "    target_data_1=df_train_.loc[:,[\"charge_0\",\"charge_1\"]]\n",
    "    target_data_2=df_train_.loc[:,[\"XX_0\",\"YY_0\",\"ZZ_0\",\"XX_1\",\"YY_1\",\"ZZ_1\"]]\n",
    "    target_data_3=df_train_.loc[:,[\"YX_0\",\"ZX_0\",\"XY_0\",\"ZY_0\",\"XZ_0\",\"YZ_0\",\"YX_1\",\"ZX_1\",\"XY_1\",\"ZY_1\",\"XZ_1\",\"YZ_1\"]]\n",
    "    \n",
    "    #following parameters should be adjusted to control the loss function\n",
    "    #if all parameters are zero, attractors do not work. (-> simple neural network)\n",
    "    m1=2\n",
    "    m2=4\n",
    "    m3=1\n",
    "    target_data_1=m1*(StandardScaler().fit_transform(target_data_1))\n",
    "    target_data_2=m2*(StandardScaler().fit_transform(target_data_2))\n",
    "    target_data_3=m3*(StandardScaler().fit_transform(target_data_3))\n",
    "    \n",
    "    # Simple split to provide us a validation set to do our CV checks with\n",
    "    #train_index, cv_index = train_test_split(np.arange(len(df_train_)),random_state=111, test_size=0.05)\n",
    "    train_index = np.where(splits != 0)[0]\n",
    "    cv_index = np.where(splits == 0)[0]\n",
    "    \n",
    "    # Split all our input and targets by train and cv indexes\n",
    "    train_input=input_data[train_index]\n",
    "    cv_input=input_data[cv_index]\n",
    "    train_target=target_data[train_index]\n",
    "    cv_target=target_data[cv_index]\n",
    "    train_target_1=target_data_1[train_index]\n",
    "    cv_target_1=target_data_1[cv_index]\n",
    "    train_target_2=target_data_2[train_index]\n",
    "    cv_target_2=target_data_2[cv_index]\n",
    "    train_target_3=target_data_3[train_index]\n",
    "    cv_target_3=target_data_3[cv_index]\n",
    "    test_input=input_data[len(df_train_):,:]\n",
    "\n",
    "    # Build the Neural Net\n",
    "    nn_model=create_nn_model(train_input.shape[1])\n",
    "    \n",
    "    # If retrain==False, then we load a previous saved model as a starting point.\n",
    "    if retrain:\n",
    "        nn_model = load_model(model_name_rd)\n",
    "        \n",
    "    nn_model.compile(loss='mae', optimizer=Adam())#, metrics=[auc])\n",
    "    #nn_model.compile(loss='mean_squared_error', optimizer=Adam())#, metrics=[auc])\n",
    "    \n",
    "    # Callback for Early Stopping... May want to raise the min_delta for small numbers of epochs\n",
    "    es = callbacks.EarlyStopping(monitor='val_out_loss', min_delta=0.0005, patience=30,verbose=1, mode='auto', restore_best_weights=True)\n",
    "    # Callback for Reducing the Learning Rate... when the monitor levels out for 'patience' epochs, then the LR is reduced\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_out_loss', factor=0.3333,patience=15, min_lr=1e-6, mode='auto', verbose=1)\n",
    "    # Save the best value of the model for future use\n",
    "    sv_mod = callbacks.ModelCheckpoint(model_name_wrt, monitor='val_out_loss', save_best_only=True, period=1)\n",
    "\n",
    "    print (train_input.shape, cv_input.shape)\n",
    "    history = nn_model.fit(train_input,[train_target,train_target_1,train_target_2,train_target_3], \n",
    "                           validation_data=(cv_input,[cv_target,cv_target_1,cv_target_2,cv_target_3]), \n",
    "                           callbacks=[es, rlr, sv_mod],\n",
    "                           epochs=epoch_n,\n",
    "                           batch_size=batch_size,\n",
    "                           verbose=verbose)\n",
    "    \n",
    "    cv_predict=nn_model.predict(cv_input)\n",
    "    plot_history(history, mol_type)\n",
    "    \n",
    "    accuracy=np.mean(np.abs(cv_target-cv_predict[0][:,0]))\n",
    "    print( accuracy,np.log(accuracy) )\n",
    "    \n",
    "    cv_score.append(np.log(accuracy))\n",
    "    cv_score_total+=np.log(accuracy)\n",
    "    \n",
    "    # Predict on the test data set using our trained model\n",
    "    test_predict=nn_model.predict(test_input)\n",
    "    \n",
    "    # for each molecule type we'll grab the predicted values\n",
    "    test_prediction[df_test[\"type\"]==mol_type]=test_predict[0][:,0]\n",
    "    K.clear_session()\n",
    "\n",
    "cv_score_total/=len(mol_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plot_history(history, mol_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time:  3:43:13.005300\n",
      "1JHC : cv score is  -0.8547819\n",
      "total cv score is -0.8547819256782532\n"
     ]
    }
   ],
   "source": [
    "print ('Total training time: ', datetime.now() - start_time)\n",
    "\n",
    "i=0\n",
    "for mol_type in mol_types: \n",
    "    print(mol_type,\": cv score is \",cv_score[i])\n",
    "    i+=1\n",
    "print(\"total cv score is\",cv_score_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare results for Submission\n",
    "\n",
    "The total CV score matches Kaggle's score pretty closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(predictions):\n",
    "    submit = pd.read_csv('../input/sample_submission.csv')\n",
    "    print(len(submit), len(predictions))   \n",
    "    submit[\"scalar_coupling_constant\"] = predictions\n",
    "    submit.to_csv(\"../submissions/keras-neural-net-1.csv\", index=False)\n",
    "submit(test_prediction)\n",
    "\n",
    "print ('Total training time: ', datetime.now() - start_time)\n",
    "\n",
    "i=0\n",
    "for mol_type in mol_types: \n",
    "    print(mol_type,\": cv score is \",cv_score[i])\n",
    "    i+=1\n",
    "print(\"total cv score is\",cv_score_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_types=df_train[\"type\"].unique()\n",
    "cv_score=[]\n",
    "cv_score_total=0\n",
    "epoch_n = 50\n",
    "verbose = 2\n",
    "batch_size = 512\n",
    "    \n",
    "# Set to True if we want to train from scratch.  False will reuse saved models as a starting point.\n",
    "retrain = True\n",
    "\n",
    "\n",
    "# Set up GPU preferences\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 2} ) \n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "sess = tf.Session(config=config) \n",
    "K.set_session(sess)\n",
    "\n",
    "start_time=datetime.now()\n",
    "\n",
    "# Loop through each molecule type\n",
    "for mol_type in mol_types:\n",
    "    model_name_rd = ('../keras-neural-net-for-champs/molecule_model_%s.hdf5' % mol_type)\n",
    "    model_name_wrt = ('working/molecule_model_%s.hdf5' % mol_type)\n",
    "    print('Training %s' % mol_type, 'out of', mol_types, '\\n')\n",
    "    \n",
    "    df_train_ = df_train[df_train[\"type\"]==mol_type]\n",
    "    df_test_  = df_test [ df_test[\"type\"]==mol_type]\n",
    "\n",
    "    # Here's our best features.  We think.\n",
    "    input_features=[\n",
    "        \"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\",\"c_x\",\"c_y\",\"c_z\",\n",
    "                    'x_closest_0','y_closest_0','z_closest_0','x_closest_1','y_closest_1','z_closest_1',\n",
    "                    \"distance\",\"distance_center0\",\"distance_center1\", \"distance_c0\",\"distance_c1\",\"distance_f0\",\"distance_f1\",\n",
    "                    \"cos_c0_c1\",\"cos_f0_f1\",\"cos_center0_center1\",\"cos_c0\",\"cos_c1\",\"cos_f0\",\"cos_f1\",\"cos_center0\",\"cos_center1\",\n",
    "                    \"atom_n\",\n",
    "                        'link0', 'dist_xyz', 'inv_dist0',\n",
    "       'inv_dist1', 'inv_distP', 'inv_dist0R', 'inv_dist1R', 'inv_distPR',\n",
    "       'inv_dist0E', 'linkM0', 'min_molecule_atom_0_dist_xyz',\n",
    "       'mean_molecule_atom_0_dist_xyz', 'max_molecule_atom_0_dist_xyz',\n",
    "       'sd_molecule_atom_0_dist_xyz', 'min_molecule_atom_1_dist_xyz',\n",
    "       'mean_molecule_atom_1_dist_xyz', 'max_molecule_atom_1_dist_xyz',\n",
    "       'distN0', 'distN1', 'bond_lengths_mean_y', 'bond_lengths_std_y',\n",
    "       'yukawa_C.x', 'yukawa_H.x', 'yukawa_N.x', 'yukawa_O.x', 'yukawa_C.y',\n",
    "       'yukawa_H.y', 'yukawa_N.y', 'yukawa_O.y', 'qm9_1', 'qm9_2', 'adH1',\n",
    "       'adC1', 'adC2', 'adC3', 'adC4', 'adC5', 'adN1', 'adN2', 'F1dist1',\n",
    "       'F1dist2', 'F1dist3', 'bond_atom', 'bond_distance', 'tertiary_angle_0',\n",
    "       'tertiary_angle_1', 'tertiary_angle_2', 'tertiary_angle_3',\n",
    "       'tertiary_angle_4', 'tertiary_angle_5', 'tertiary_angle_6',\n",
    "       'tertiary_angle_7', 'tertiary_distance_0', 'tertiary_distance_1',\n",
    "       'tertiary_distance_2', 'tertiary_distance_3', 'tertiary_distance_4',\n",
    "       'tertiary_distance_5', 'tertiary_distance_6', 'tertiary_distance_7',\n",
    "    ]\n",
    "\n",
    "    # Standard Scaler from sklearn does seem to work better here than other Scalers\n",
    "    input_data=StandardScaler().fit_transform(pd.concat([df_train_.loc[:,input_features],df_test_.loc[:,input_features]]))\n",
    "    \n",
    "    target_data=df_train_.loc[:,\"scalar_coupling_constant\"].values\n",
    "    target_data_1=df_train_.loc[:,[\"charge_0\",\"charge_1\"]]\n",
    "    target_data_2=df_train_.loc[:,[\"XX_0\",\"YY_0\",\"ZZ_0\",\"XX_1\",\"YY_1\",\"ZZ_1\"]]\n",
    "    target_data_3=df_train_.loc[:,[\"YX_0\",\"ZX_0\",\"XY_0\",\"ZY_0\",\"XZ_0\",\"YZ_0\",\"YX_1\",\"ZX_1\",\"XY_1\",\"ZY_1\",\"XZ_1\",\"YZ_1\"]]\n",
    "    \n",
    "    #following parameters should be adjusted to control the loss function\n",
    "    #if all parameters are zero, attractors do not work. (-> simple neural network)\n",
    "    m1=2\n",
    "    m2=4\n",
    "    m3=1\n",
    "    target_data_1=m1*(StandardScaler().fit_transform(target_data_1))\n",
    "    target_data_2=m2*(StandardScaler().fit_transform(target_data_2))\n",
    "    target_data_3=m3*(StandardScaler().fit_transform(target_data_3))\n",
    "    \n",
    "    # Simple split to provide us a validation set to do our CV checks with\n",
    "    train_index, cv_index = train_test_split(np.arange(len(df_train_)),random_state=111, test_size=0.05)\n",
    "    \n",
    "    # Split all our input and targets by train and cv indexes\n",
    "    train_input=input_data[train_index]\n",
    "    cv_input=input_data[cv_index]\n",
    "    train_target=target_data[train_index]\n",
    "    cv_target=target_data[cv_index]\n",
    "    train_target_1=target_data_1[train_index]\n",
    "    cv_target_1=target_data_1[cv_index]\n",
    "    train_target_2=target_data_2[train_index]\n",
    "    cv_target_2=target_data_2[cv_index]\n",
    "    train_target_3=target_data_3[train_index]\n",
    "    cv_target_3=target_data_3[cv_index]\n",
    "    test_input=input_data[len(df_train_):,:]\n",
    "\n",
    "    # Build the Neural Net\n",
    "    nn_model=create_nn_model(train_input.shape[1])\n",
    "    \n",
    "    # If retrain==False, then we load a previous saved model as a starting point.\n",
    "    #if not retrain:\n",
    "    nn_model = load_model(model_name_rd)\n",
    "        \n",
    "    nn_model.compile(loss='mae', optimizer=Adam(lr=0.00001))#, metrics=[auc])\n",
    "    #nn_model.compile(loss='mean_squared_error', optimizer=Adam())#, metrics=[auc])\n",
    "    \n",
    "    # Callback for Early Stopping... May want to raise the min_delta for small numbers of epochs\n",
    "    es = callbacks.EarlyStopping(monitor='val_out_loss', min_delta=0.0005, patience=30,verbose=1, mode='auto', restore_best_weights=True)\n",
    "    # Callback for Reducing the Learning Rate... when the monitor levels out for 'patience' epochs, then the LR is reduced\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_out_loss', factor=0.3333,patience=15, min_lr=1e-6, mode='auto', verbose=1)\n",
    "    # Save the best value of the model for future use\n",
    "    sv_mod = callbacks.ModelCheckpoint(model_name_wrt, monitor='val_out_loss', save_best_only=True, period=1)\n",
    "\n",
    "    history = nn_model.fit(train_input,[train_target,train_target_1,train_target_2,train_target_3], \n",
    "                           validation_data=(cv_input,[cv_target,cv_target_1,cv_target_2,cv_target_3]), \n",
    "                           callbacks=[es, rlr, sv_mod],\n",
    "                           epochs=epoch_n,\n",
    "                           batch_size=batch_size,\n",
    "                           verbose=verbose)\n",
    "    \n",
    "    cv_predict=nn_model.predict(cv_input)\n",
    "    plot_history(history, mol_type)\n",
    "    \n",
    "    accuracy=np.mean(np.abs(cv_target-cv_predict[0][:,0]))\n",
    "    print( accuracy,np.log(accuracy) )\n",
    "    \n",
    "    cv_score.append(np.log(accuracy))\n",
    "    cv_score_total+=np.log(accuracy)\n",
    "    \n",
    "    # Predict on the test data set using our trained model\n",
    "    test_predict=nn_model.predict(test_input)\n",
    "    \n",
    "    # for each molecule type we'll grab the predicted values\n",
    "    test_prediction[df_test[\"type\"]==mol_type]=test_predict[0][:,0]\n",
    "    K.clear_session()\n",
    "\n",
    "cv_score_total/=len(mol_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test), len(test_prediction[df_test[\"type\"]==mol_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1JHC : cv score is  -0.60937184\n",
    "# 2JHH : cv score is  -2.0246258\n",
    "# 1JHN : cv score is  -1.3377854\n",
    "# 2JHN : cv score is  -2.0205796\n",
    "# 2JHC : cv score is  -1.4633688\n",
    "# 3JHH : cv score is  -1.8357394\n",
    "# 3JHC : cv score is  -1.4595399\n",
    "# 3JHN : cv score is  -2.2611656\n",
    "# total cv score is -1.6265220269560814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(predictions):\n",
    "    submit = pd.read_csv('../input/sample_submission.csv')\n",
    "    print(len(submit), len(predictions))   \n",
    "    submit[\"scalar_coupling_constant\"] = predictions\n",
    "    submit.to_csv(\"../submissions/keras-neural-net-1-ft.csv\", index=False)\n",
    "submit(test_prediction)\n",
    "\n",
    "print ('Total training time: ', datetime.now() - start_time)\n",
    "\n",
    "i=0\n",
    "for mol_type in mol_types: \n",
    "    print(mol_type,\": cv score is \",cv_score[i])\n",
    "    i+=1\n",
    "print(\"total cv score is\",cv_score_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
