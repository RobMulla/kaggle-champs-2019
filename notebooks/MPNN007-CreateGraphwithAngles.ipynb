{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "datadir = \"../input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(datadir + 'train.csv')\n",
    "test = pd.read_csv(datadir + 'test.csv')\n",
    "structures = pd.read_csv(datadir + 'structures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bonds = pd.read_csv('../data/MPNN/train_bonds.csv')\n",
    "test_bonds = pd.read_csv('../data/MPNN/test_bonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_angs = pd.read_csv('../data/MPNN/angles_train.csv')\n",
    "test_angs = pd.read_csv('../data/MPNN/angles_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_min  = train['scalar_coupling_constant'].min()\n",
    "scale_max  = train['scalar_coupling_constant'].max()\n",
    "scale_mid = (scale_max + scale_min)/2\n",
    "scale_norm = scale_max - scale_mid\n",
    "\n",
    "train['scalar_coupling_constant'] = (train['scalar_coupling_constant'] - scale_mid)/scale_norm\n",
    "\n",
    "# One hot encoding gets  too big for Kaggle, let's try label\n",
    "# use npz now, back to OH\n",
    "train[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']] =  pd.get_dummies(train['type'])\n",
    "test[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']]  =  pd.get_dummies(test['type'])\n",
    "\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit(['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN'])\n",
    "#train['l_type'] = (le.transform(train['type']) + 1)/8.\n",
    "#test['l_type'] = (le.transform(test['type']) + 1)/8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures[['C', 'F' ,'H', 'N', 'O']] = pd.get_dummies(structures['atom'])\n",
    "structures[['x', 'y', 'z']] = structures[['x', 'y', 'z']]/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bonds[['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']] = pd.get_dummies(test_bonds['nbond'])#test_bonds['nbond']/3\n",
    "train_bonds[['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']] = pd.get_dummies(train_bonds['nbond'])#train_bonds['nbond']/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mol_names = train['molecule_name'].unique()\n",
    "test_mol_names  = test['molecule_name'].unique()\n",
    "\n",
    "train_structures = structures.loc[structures['molecule_name'].isin(train_mol_names)]\n",
    "test_structures = structures.loc[structures['molecule_name'].isin(test_mol_names)]\n",
    "\n",
    "train_struct_group = train_structures.groupby('molecule_name')\n",
    "test_struct_group  = test_structures.groupby('molecule_name')\n",
    "\n",
    "train_group = train.groupby('molecule_name')\n",
    "test_group  = test.groupby('molecule_name')\n",
    "\n",
    "train_bond_group = train_bonds.groupby('molecule_name')\n",
    "test_bond_group  = test_bonds.groupby('molecule_name')\n",
    "\n",
    "#train_angs = angs.loc[angs['molecule_name'].isin(train_mol_names)]\n",
    "#test_angs = angs.loc[angs['molecule_name'].isin(test_mol_names)]\n",
    "\n",
    "train_angs_group = train_angs.groupby('molecule_name')\n",
    "test_angs_group  = test_angs.groupby('molecule_name')\n",
    "\n",
    "# Find max nodes in graph:\n",
    "max_size = train_struct_group.size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['molecule_name', 'atom_index_0', 'atom_index_1', 'ang0', 'ang1', 'ang2',\n",
       "       'ang3', 'ang4', 'ang5', 'ang6', 'ang7', 'ang8', 'ang9', 'ang10',\n",
       "       'ang11', 'ang12', 'ang13', 'ang14', 'ang15', 'ang16', 'ang17', 'ang18',\n",
       "       'ang19', 'ang20', 'ang21', 'ang22', 'ang23', 'ang24', 'ang25', 'ang26',\n",
       "       'ang27', 'ang28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_angs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values our nodes will have\n",
    "node_vals = ['C', 'F' ,'H', 'N', 'O']#, 'x', 'y', 'z']\n",
    "#Values our edges will have (minus distance, for now)\n",
    "bond_vals = ['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']#['nbond']\n",
    "j_coup_vals = ['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']#'l_type']\n",
    "ang_vals = ['ang0', 'ang1', 'ang2',\n",
    "       'ang3', 'ang4', 'ang5', 'ang6', 'ang7', 'ang8', 'ang9', 'ang10',\n",
    "       'ang11', 'ang12', 'ang13', 'ang14', 'ang15', 'ang16', 'ang17', 'ang18',\n",
    "       'ang19', 'ang20', 'ang21', 'ang22', 'ang23', 'ang24', 'ang25', 'ang26',\n",
    "       'ang27', 'ang28']\n",
    "edge_vals = j_coup_vals + bond_vals + ang_vals\n",
    "\n",
    "# Find amount of training molecules\n",
    "n_train_mols = len(train_mol_names)\n",
    "n_test_mols = len(test_mol_names)\n",
    "\n",
    "# Find dim of edges and nodes\n",
    "bond_dim  = len(bond_vals)\n",
    "j_coup_dim= len(j_coup_vals)\n",
    "ang_dim   = len(ang_vals)\n",
    "node_dim  = len(node_vals)\n",
    "edge_dim  = len(edge_vals) \n",
    "\n",
    "# Additional edge dims for distances \n",
    "add_edge_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes_array     = np.zeros((n_train_mols, max_size, node_dim), dtype=np.float32) \n",
    "train_in_edges_array  = np.zeros((n_train_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) \n",
    "train_out_edges_array = np.zeros((n_train_mols, max_size, max_size, 1),dtype=np.float32) \n",
    "\n",
    "test_nodes_array     = np.zeros((n_test_mols, max_size, node_dim), dtype=np.float32) \n",
    "test_in_edges_array  = np.zeros((n_test_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arrs(val_group, struct_group, bond_group, ang_group, test):\n",
    "    i = 0\n",
    "    for values, structs, bonds, angles in zip(val_group, struct_group, bond_group, ang_group):\n",
    "        if (not i%1000):\n",
    "            print(i)\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = np.zeros((max_size, max_size, 1))\n",
    "        coords = structs[1][['x','y','z']].values\n",
    "        dists  = distance_matrix(coords, coords)\n",
    "        distances[:dists.shape[0],:dists.shape[1], 0] = dists \n",
    "        \n",
    "        # Create nodes\n",
    "        mol_info = structs[1][node_vals].values\n",
    "        nodes = np.zeros((max_size, node_dim))\n",
    "        nodes[:mol_info.shape[0], :mol_info.shape[1]] = mol_info\n",
    "\n",
    "        # Create edges\n",
    "        in_feats = np.zeros((max_size, max_size, j_coup_dim))\n",
    "        ind = values[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        in_feats[ind[:,0], ind[:,1], 0:j_coup_dim] = values[1][j_coup_vals].values\n",
    "        in_feats[ind[:,1], ind[:,0], 0:j_coup_dim] = in_feats[ind[:,0], ind[:,1], 0:j_coup_dim]\n",
    "\n",
    "        # Create bonds\n",
    "        in_bonds = np.zeros((max_size, max_size, bond_dim))\n",
    "        ind_bonds = bonds[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        in_bonds[ind_bonds[:,0], ind_bonds[:,1]] = bonds[1][bond_vals].values\n",
    "        in_bonds[ind_bonds[:,1], ind_bonds[:,0]] = in_bonds[ind_bonds[:,0], ind_bonds[:,1]]\n",
    "        \n",
    "        # Create angles\n",
    "        ind_angs = angles[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        ang_mat  = np.zeros((max_size, max_size, ang_dim))\n",
    "        ang_mat[ind_angs[:,0], ind_angs[:,1]]  = angles[1][ang_vals]\n",
    "        ang_mat[ind_angs[:,1], ind_angs[:,0]]  = ang_mat[ind_angs[:,0], ind_angs[:,1]]\n",
    "        \n",
    "        # concat all edge values \n",
    "        in_edges = np.concatenate((in_feats, in_bonds, ang_mat, distances),axis=2)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if not test:           \n",
    "            out_edges = np.zeros((max_size, max_size, 1))\n",
    "            out_edges[ind[:,0], ind[:,1], 0] = values[1]['scalar_coupling_constant' ].values\n",
    "            out_edges[ind[:,1], ind[:,0], 0] = out_edges[ind[:,0], ind[:,1], 0]\n",
    "        \n",
    "\n",
    "            train_nodes_array[i]      = nodes\n",
    "            train_in_edges_array[i]   = in_edges\n",
    "            train_out_edges_array[i]  = out_edges\n",
    "        else:\n",
    "            test_nodes_array[i]      = nodes\n",
    "            test_in_edges_array[i]   = in_edges\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n"
     ]
    }
   ],
   "source": [
    "make_arrs(train_group, train_struct_group, train_bond_group, train_angs_group, test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "make_arrs(test_group, test_struct_group, test_bond_group, test_angs_group, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../data/MPNN/MPNN007-nodes_train.npz\" , train_nodes_array)\n",
    "np.savez_compressed(\"../data/MPNN/MPNN007-in_edges_train.npz\" , train_in_edges_array)\n",
    "np.savez_compressed(\"../data/MPNN/MPNN007-out_edges_train.npz\" , train_out_edges_array)\n",
    "\n",
    "np.savez_compressed(\"../data/MPNN/MPNN007-nodes_test.npz\" , test_nodes_array)\n",
    "np.savez_compressed(\"../data/MPNN/MPNN007-in_edges_test.npz\" , test_in_edges_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
