{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEND019\n",
    "\n",
    "- Automate the Blend Weight Selection\n",
    "- Only Use 3 Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def group_mean_log_mae(y_true, y_pred, groups, floor=1e-9):\n",
    "    maes = (y_true-y_pred).abs().groupby(groups).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
    "\n",
    "def log_mean_absolute_error(y_true, y_pred):\n",
    "    return np.log(mean_absolute_error(y_true, y_pred))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JHC: Running for type 1JHC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/5000 [00:00<03:32, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JHC: Has model names ['M047-0.7977', 'M048-0.8258']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1091/5000 [00:34<02:01, 32.15it/s]"
     ]
    }
   ],
   "source": [
    "types = ['1JHC', '2JHH', '1JHN', '2JHN', '2JHC','3JHH','3JHC', '3JHN']\n",
    "\n",
    "def get_sub_oof(t):\n",
    "    \"\"\"\n",
    "    Grab the sub and oof files for a give type. \n",
    "    \"\"\"\n",
    "    oof = []\n",
    "    sub = []\n",
    "    model_ids = []\n",
    "    for file in sorted(os.listdir(f'../type_results/{t}/')):\n",
    "        if ('sub' in file) and ('3folds' in file):\n",
    "            model_id = file[:4] + file.split('MAE_')[1].replace('L','')\n",
    "            model_ids.append(model_id)\n",
    "            df = pd.read_parquet(f'../type_results/{t}/{file}')\n",
    "            if len(sub) == 0:\n",
    "                sub = df.rename(columns={'scalar_coupling_constant': model_id})\n",
    "            else:\n",
    "                sub[model_id] = df['scalar_coupling_constant']\n",
    "        elif ('oof' in file) and ('3folds' in file):\n",
    "            model_id = file[:4] + file.split('MAE_')[1].replace('L','')\n",
    "            #print(model_id)\n",
    "            df = pd.read_parquet(f'../type_results/{t}/{file}')\n",
    "            if len(oof) == 0:\n",
    "                oof = df.rename(columns={'oof_preds': model_id})\n",
    "            else:\n",
    "                oof[model_id] = df['oof_preds']\n",
    "    sub = sub.loc[sub['type'] == t]\n",
    "    oof = oof.loc[oof['type'] == t]\n",
    "    return sub, oof, model_ids\n",
    "\n",
    "def get_best_weights(oof, l5, t):\n",
    "    if len(l5) == 1:\n",
    "        return [1]\n",
    "    lmae_best = 0\n",
    "    for x in tqdm(range(0, 5000)):\n",
    "        ws = []\n",
    "        for x in range(0, len(l5)):\n",
    "            if x == len(l5)-1:\n",
    "                ws.append(random.randint(1, 50))\n",
    "            else:\n",
    "                ws.append(random.randint(0, 50))\n",
    "        idx = 0\n",
    "        blend = np.zeros(len(oof[l5[0]]))\n",
    "        for w in ws:\n",
    "            blend += w * oof[l5[idx]]\n",
    "            idx += 1\n",
    "        blend = blend / np.sum(ws)\n",
    "        lmae = log_mean_absolute_error(oof['scalar_coupling_constant'],\n",
    "                            blend)\n",
    "        if lmae < lmae_best:\n",
    "            lmae_best = lmae\n",
    "            bws = ws\n",
    "    print(f'{t}: Best score {lmae:0.5f} - with weights {bws}')\n",
    "    return bws # Return the best weights\n",
    "\n",
    "def create_best_blends():\n",
    "    oofs = []\n",
    "    subs = []\n",
    "    for t in types:\n",
    "        print(f'{t}: Running for type {t}')\n",
    "        tsub, toof, tmodel_ids = get_sub_oof(t)\n",
    "        print(f'{t}: Has model names {tmodel_ids}')\n",
    "        l5 = tmodel_ids[-5:] # Last 5 models\n",
    "        bws = get_best_weights(toof, l5, t)\n",
    "        tot_weight = np.sum(bws)\n",
    "        tsub['scalar_coupling_constant'] = 0\n",
    "        toof['oof_blend'] = 0\n",
    "        idx = 0\n",
    "        for w in bws:\n",
    "            tsub['scalar_coupling_constant'] += (w * tsub[l5[idx]])\n",
    "            toof['oof_blend'] += (w * toof[l5[idx]])\n",
    "            idx += 1\n",
    "        tsub['scalar_coupling_constant'] /= tot_weight\n",
    "        toof['oof_blend'] /= tot_weight\n",
    "        tsub = tsub[['id','molecule_name','type','scalar_coupling_constant']].copy()\n",
    "        toof = toof[['id','type','scalar_coupling_constant','oof_blend']].copy()\n",
    "        subs.append(tsub)\n",
    "        oofs.append(toof)\n",
    "    final_oof = pd.concat(oofs).sort_values('id').reset_index(drop=True)\n",
    "    final_sub = pd.concat(subs).sort_values('id').reset_index(drop=True)\n",
    "    return final_oof, final_sub\n",
    "    \n",
    "final_oof, final_sub = create_best_blends()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JHC 0.40569\n",
      "1JHN 0.23375\n",
      "2JHC 0.16186\n",
      "2JHH 0.08987\n",
      "2JHN 0.09972\n",
      "3JHC 0.19953\n",
      "3JHH 0.10608\n",
      "3JHN 0.08749\n",
      "\n",
      "Group LMAE\n",
      "-1.89788\n"
     ]
    }
   ],
   "source": [
    "for i, d in final_oof.groupby('type'):\n",
    "    print(i, '{:0.5f}'.format(mean_absolute_error(d['scalar_coupling_constant'], d['oof_blend'])))\n",
    "glmae = group_mean_log_mae(final_oof['scalar_coupling_constant'], final_oof['oof_blend'], final_oof['type'])\n",
    "print('\\nGroup LMAE')\n",
    "print('{:0.5f}'.format(glmae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>good_scc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good_scc</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          scalar_coupling_constant  good_scc\n",
       "scalar_coupling_constant                  1.000000  0.999996\n",
       "good_scc                                  0.999996  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_good = pd.read_csv('../submissions/BLEND014_sub_-1.85550CV.csv')\n",
    "final_sub['good_scc'] = sub_good['scalar_coupling_constant']\n",
    "final_sub[['scalar_coupling_constant','good_scc']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute(`notebookName = '${window.document.getElementById(\"notebook_name\").innerHTML}'`);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute(`notebookName = '${window.document.getElementById(\"notebook_name\").innerHTML}'`);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission and OOF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import re\n",
    "import ipykernel\n",
    "import requests\n",
    "\n",
    "#try:  # Python 3\n",
    "#    from urllib.parse import urljoin\n",
    "#except ImportError:  # Python 2\n",
    "#    from urlparse import urljoin\n",
    "\n",
    "# Alternative that works for both Python 2 and 3:\n",
    "from requests.compat import urljoin\n",
    "\n",
    "try:  # Python 3 (see Edit2 below for why this may not work in Python 2)\n",
    "    from notebook.notebookapp import list_running_servers\n",
    "except ImportError:  # Python 2\n",
    "    import warnings\n",
    "    from IPython.utils.shimmodule import ShimWarning\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=ShimWarning)\n",
    "        from IPython.html.notebookapp import list_running_servers\n",
    "\n",
    "\n",
    "def get_notebook_name():\n",
    "    \"\"\"\n",
    "    Return the full path of the jupyter notebook.\n",
    "    \"\"\"\n",
    "    kernel_id = re.search('kernel-(.*).json',\n",
    "                          ipykernel.connect.get_connection_file()).group(1)\n",
    "    servers = list_running_servers()\n",
    "    for ss in servers:\n",
    "        response = requests.get(urljoin(ss['url'], 'api/sessions'),\n",
    "                                params={'token': ss.get('token', '')})\n",
    "        for nn in json.loads(response.text):\n",
    "            if nn['kernel']['id'] == kernel_id:\n",
    "                relative_path = nn['notebook']['path']\n",
    "                return os.path.join(ss['notebook_dir'], relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME TO SAVE BLEND018\n"
     ]
    }
   ],
   "source": [
    "BLEND_NUMBER = get_notebook_name().split('/')[-1].replace('.ipynb','').replace('-','')\n",
    "print(f'NAME TO SAVE {BLEND_NUMBER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Results\n",
    "final_sub[['id','scalar_coupling_constant']].to_csv(f'../submissions/{BLEND_NUMBER}_sub_{glmae:0.5f}CV.csv', index=False)\n",
    "final_oof.to_csv(f'../oof/{BLEND_NUMBER}_oof_{glmae:0.5f}CV.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
